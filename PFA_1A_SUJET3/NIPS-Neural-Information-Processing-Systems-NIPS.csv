Title
Modelling sparsity heterogeneity; reciprocity and community structure in temporal interaction data
The Lingering of Gradients: How to Reuse Gradients Over Time
Quadratic Decomposable Submodular Function Minimization
On the Global Convergence of Gradient Descent for Over-parameterized Models using Optimal Transport
Leveraging the Exact Likelihood of Deep Latent Variable Models
DVAE: Discrete Variational Autoencoders with Relaxed Boltzmann Priors
Amortized Inference Regularization
Generalizing Point Embeddings using the Wasserstein Space of Elliptical Distributions
On gradient regularizers for MMD GANs
PacGAN: The power of two samples in generative adversarial networks
Adversarial Scene Editing: Automatic Object Removal from Weak Supervision
Generalizing Point Embeddings using the Wasserstein Space of Elliptical Distributions
Banach Wasserstein GAN
A Convex Duality Framework for GANs
On the Convergence and Robustness of Training GANs with Regularized Optimal Transport
On gradient regularizers for MMD GANs
PacGAN: The power of two samples in generative adversarial networks
Are GANs Created Equal? A Large-Scale Study
Disconnected Manifold Learning for Generative Adversarial Networks
Hessian-based Analysis of Large Batch Training and Robustness to Adversaries
Fast and Effective Robustness Certification
Graphical Generative Adversarial Networks
Deep Defense: Training DNNs with Improved Adversarial Robustness
Learning to Repair Software Vulnerabilities with Generative Adversarial Networks
Memory Replay GANs Learning to Generate New Categories without Forgetting
Unsupervised Attention-guided Image-to-Image Translation
Conditional Adversarial Domain Adaptation
Video-to-Video Synthesis
Generalized Zero-Shot Learning with Deep Calibration Network
Low-shot Learning via Covariance-Preserving Adversarial Augmentation Networks
Trading robust representations for sample complexity through self-supervised visual experience
TADAM: Task dependent adaptive metric for improved few-shot learning
FishNet: A Versatile Backbone for Image Region and Pixel Level Prediction
Batch-Instance Normalization for Adaptively Style-Invariant Neural Networks
A^2-Nets: Double Attention Networks
Pelee: A Real-Time Object Detection System on Mobile Devices
PointCNN: Convolution On X-Transformed Points
Deep Neural Networks with Box Convolutions
An intriguing failing of convolutional neural networks and the CoordConv solution
3D Steerable CNNs: Learning Rotationally Equivariant Features in Volumetric Data
Moonshine: Distilling with Cheap Convolutions
Kalman Normalization: Normalizing Internal Representations Across Network Layers
SplineNets: Continuous Neural Decision Graphs
CapProNet: Deep Feature Learning via Orthogonal Projections onto Capsule Subspaces
Which Neural Net Architectures Give Rise to Exploding and Vanishing Gradients?
Exact natural gradient in deep linear networks and its application to the nonlinear case
Fast Approximate Natural Gradient Descent in a Kronecker Factored Eigenbasis
Post: Device Placement with Cross-Entropy Minimization and Proximal Policy Optimization
Paraphrasing Complex Network: Network Compression via Factor Transfer
Learning Compressed Transforms with Low Displacement Rank
Knowledge Distillation by On-the-Fly Native Ensemble
Scalable methods for 8-bit training of neural networks
Training Deep Models Faster with Robust Approximate Importance Sampling
Collaborative Learning for Deep Neural Networks
A Linear Speedup Analysis of Distributed Deep Learning with Sparse and Quantized Communication
Bayesian Distributed Stochastic Gradient Descent
Regularizing by the Variance of the Activations' Sample-Variances
BML: A High-performance: Low-cost Gradient Synchronization Algorithm for DML Training
L4: Practical loss-based stepsize adaptation for deep learning
Synaptic Strength For Convolutional Neural Network
ChannelNets: Compact and Efficient Convolutional Neural Networks via Channel-Wise Convolutions
Frequency-Domain Dynamic Pruning for Convolutional Neural Networks
TETRIS: TilE-matching the TRemendous Irregular Sparsity
Heterogeneous Bitwidth Binarization in Convolutional Neural Networks
HitNet: Hybrid Ternary Recurrent Neural Network
A General Method for Amortizing Variational Filtering
Multiple Instance Learning for Efficient Sequential Data Classification on Resource-constrained Devices
Navigating with Graph Representations for Fast and Scalable Decoding of Neural Language Models
Representer Point Selection for Explaining Deep Neural Networks
Interpreting Neural Network Judgments via Minimal ;Stable and Symbolic Corrections
DropMax: Adaptive Variational Softmax
Learning with SGD and Random Features
But How Does It Work in Theory? Linear SVM with Random Features
Statistical and Computational Trade-Offs in Kernel K-Means
Quadrature-based features for kernel approximation
Processing of missing data by neural networks
Constructing Deep Neural Networks by Bayesian Network Structure Learning
Mallows Models for Top-k Lists
Cooperative neural networks (CoNN): Exploiting prior independence structure for improved classification
Maximum-Entropy Fine Grained Classification
Efficient Loss-Based Decoding on Graphs for Extreme Classification
A no-regret generalization of hierarchical softmax to extreme multi-label classification
Efficient Gradient Computation for Structured Output Learning with Rational and Tropical Losses
Deep Structured Prediction with Nonlinear Output Transformations
Mapping Images to Scene Graphs with Permutation-Invariant Structured Prediction
Large Margin Deep Networks for Classification
Semi-supervised Deep Kernel Learning: Regression with Unlabeled Data by Minimizing Predictive Variance
Multitask Boosting for Survival Analysis with Competing Risks
Multi-Layered Gradient Boosting Decision Trees
Unsupervised Adversarial Invariance
Learning Deep Disentangled Embeddings With the F-Statistic Loss
Learning Latent Subspaces in Variational Autoencoders
Dual Swap Disentangling
Joint Autoregressive and Hierarchical Priors for Learned Image Compression
Group Equivariant Capsule Network
Learning Disentangled Joint Continuous and Discrete Representations
Image-to-image translation for cross-domain disentanglement
Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization
Non-Adversarial Mapping with VAEs
Learning to Teach with Dynamic Loss Functions
Maximizing acquisition functions for Bayesian optimization
MetaReg: Towards Domain Generalization using Meta-Regularization
Transfer Learning with Neural AutoML
Hierarchical Reinforcement Learning for Zero-shot Generalization with Subtask Dependencies
Lifelong Inverse Reinforcement Learning
Safe Active Learning for Time-Series Modeling with Gaussian Processes
Online Structure Learning for Feed-Forward and Recurrent Sum-Product Networks
Preference Based Adaptation for Learning Objectives
Byzantine Stochastic Gradient Descent
Contextual bandits with surrogate losses: Margin bounds and efficient algorithms
conferences knowledge mining
